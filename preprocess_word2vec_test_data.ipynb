{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess questions-words-norwgian\n",
    "\n",
    "The file 'questions-words-norwegian' is just a google tranlate of the file http://word2vec.googlecode.com/svn/trunk/questions-words.txt.\n",
    "\n",
    "One row is already removed as it contained a lot or words, and seem to just be added randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Clean_question_words(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.remove_idx = set()\n",
    "        self._len_file = None\n",
    "        self.categories = None\n",
    "    def __iter__(self):\n",
    "        with codecs.open(self.filename, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                yield line\n",
    "    def add_to_remove_idx(self, idx):\n",
    "        for i in idx:\n",
    "            self.remove_idx.add(i)\n",
    "    def _is_category(self, line):\n",
    "        if line.split()[0] == u':':\n",
    "            return True\n",
    "        return False\n",
    "    def shape(self):\n",
    "        \"\"\"(lines_in_file, lines_not_scheduled_to_be_removed)\"\"\"\n",
    "        if self._len_file is None:\n",
    "            self._len_file = 0\n",
    "            for line in self:\n",
    "                self._len_file += 1\n",
    "        return self._len_file, (self._len_file - len(self.remove_idx))\n",
    "    def not_2and2_unique_words(self):\n",
    "        \"\"\"\n",
    "        Return index of lines that are not tags ':<tag>' or contain\n",
    "        2 different words followd by two different words.\n",
    "        \"\"\"\n",
    "        for i, line in enumerate(self):\n",
    "            words = line.split()\n",
    "            if self._is_category(line):\n",
    "                continue\n",
    "            if len(words) != 4:\n",
    "                self.remove_idx.add(i)\n",
    "                continue\n",
    "            if (words[0] == words[1]) or (words[2] == words[3]):\n",
    "                self.remove_idx.add(i)\n",
    "        return self.remove_idx\n",
    "    def print_lines(self, idx):\n",
    "        \"\"\"Print lines with idx\"\"\"\n",
    "        for i, line in enumerate(self):\n",
    "            if i in idx:\n",
    "                print line\n",
    "    def write_to_file(self, filename):\n",
    "        with codecs.open(filename, 'w', encoding='utf-8') as f:\n",
    "            for line in self.__iter__remove_idx():\n",
    "                f.write(line)\n",
    "    def __iter__remove_idx(self):\n",
    "        for i, line in enumerate(self):\n",
    "            if i not in self.remove_idx:\n",
    "                yield line\n",
    "    def get_unique_pairs(self, idx=None):\n",
    "        self.unique_pairs = set()\n",
    "        for line in self.__iter__remove_idx():\n",
    "            if not self._is_category(line):\n",
    "                words = line.split()\n",
    "                self.unique_pairs.add(' '.join(words[:2]))\n",
    "                self.unique_pairs.add(' '.join(words[2:]))\n",
    "        return self.unique_pairs\n",
    "    def get_categories(self):\n",
    "        \"\"\"Returns dict of categories with line numbers 0 indexed\"\"\"\n",
    "        cat = []\n",
    "        idx = []\n",
    "        for i, line in enumerate(self):\n",
    "            if self._is_category(line):\n",
    "                cat.append(line)\n",
    "                idx.append(i)\n",
    "        idx.append(i)\n",
    "        self.categories = {}\n",
    "        for c, start, end in zip(cat, idx[:-1], idx[1:]):\n",
    "            self.categories[c] = [start, end-1]\n",
    "        return self.categories\n",
    "    def get_unique_in_categories(self):\n",
    "        if self.categories is None:\n",
    "            self.get_categories()\n",
    "        unique_pairs_in_cat = {}\n",
    "        cur_cat = ''\n",
    "        for line in self.__iter__remove_idx():\n",
    "            if self._is_category(line):\n",
    "                cur_cat = line\n",
    "                unique_pairs_in_cat[line] = set()\n",
    "                continue\n",
    "            unique_pairs_in_cat[cur_cat].add(' '.join(line.split()[:2]))\n",
    "            unique_pairs_in_cat[cur_cat].add(' '.join(line.split()[2:]))\n",
    "        return unique_pairs_in_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check similarity between english and engish-norwegian-english\n",
    "\n",
    "'questions-words_transEn-No-En.txt' is translated to norwegian and back again. By comparing it to the original, we can say something about the quality of the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en = Clean_question_words('./data/questions-words.txt')\n",
    "enNoEn = Clean_question_words('./data/questions-words_transEn_No_En.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8539, 11019)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = set()\n",
    "remove_idx = set()\n",
    "for i, (e, ene) in enumerate(zip(en, enNoEn)):\n",
    "    if (e.split() == ene.split()) or (en._is_category(e)) :\n",
    "        idx.add(i)\n",
    "    else:\n",
    "        remove_idx.add(i)\n",
    "len(idx), len(remove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del en, enNoEn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the norwegian data\n",
    "- We can now remove all rows that didn't wasn't equal in 'questions-words.txt' and 'questions-words_transEn_No_En.txt'.\n",
    "- We check that all lines contain 4 words, the the first and second pair in every line contain uique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qwn = Clean_question_words('./data/questions-words-norwegian.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qwn.add_to_remove_idx(remove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11108"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_idx = qwn.not_2and2_unique_words()\n",
    "len(remove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qwn.write_to_file('./data/questions-words-norwegian_cleaned.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del qwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8450  33777 277397 data/questions-words-norwegian_cleaned.txt\r\n"
     ]
    }
   ],
   "source": [
    "! wc data/questions-words-norwegian_cleaned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": Kapital-common-land \r\n",
      "Athen Hellas Bangkok Thailand \r\n",
      "Athen Hellas Beijing Kina \r\n",
      "Athen Hellas Berlin Tyskland \r\n",
      "Athen Hellas Bern Sveits \r\n",
      "Athen Hellas Kairo Egypt \r\n",
      "Athen Hellas Canberra Australia \r\n",
      "Athen Hellas Havana Cuba \r\n",
      "Athen Hellas Helsingfors Finland \r\n",
      "Athen Hellas London England \r\n"
     ]
    }
   ],
   "source": [
    "! head data/questions-words-norwegian_cleaned.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand cleaning\n",
    "\n",
    "We can now inspect the lines and remove those that does not make sence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qwn = Clean_question_words('./data/questions-words-norwegian_cleaned.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique word pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qwn.get_unique_pairs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of examples in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 \t: gram2-motsatte \n",
      "60 \t: gram1-adjektiv til adverb \n",
      "2743 \t: kapital verden \n",
      "869 \t: gram6 -nationality-adjektiv \n",
      "13 \t: gram9-flertall-verb \n",
      "515 \t: gram4-superlativ \n",
      "48 \t: gram7-fortid-anspent \n",
      "61 \t: gram5-stede-partisipp \n",
      "248 \t: familie \n",
      "414 \t: gram3 -comparative \n",
      "257 \t: Kapital-common-land \n",
      "249 \t: valuta \n",
      "2361 \t: city-in-state \n",
      "468 \t: gram8-flertall \n"
     ]
    }
   ],
   "source": [
    "cat = qwn.get_categories()\n",
    "for c, r in cat.iteritems():\n",
    "    print r[1]-r[0], '\\t', c[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_cat = qwn.get_unique_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generere genererer\n",
      "implementere redskaper\n",
      "forsvinne vanishes\n",
      "se ser\n",
      "anslå estimater\n",
      "forutsi spår\n",
      "spise spiser\n",
      "beskrive beskriver\n",
      "skrive skriver\n"
     ]
    }
   ],
   "source": [
    "for pair in unique_cat[': gram9-flertall-verb \\n']:\n",
    "    print pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
